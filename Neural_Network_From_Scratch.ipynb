{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidmetikala-dev/nn-from-scratch/blob/main/Neural_Network_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\", header = None)\n",
        "test = pd.read_csv(\"/content/sample_data/mnist_test.csv\", header = None)\n"
      ],
      "metadata": {
        "id": "EO2mt63lPMjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_output, train_input = train.iloc[:, 0], train.iloc[:, 1:]\n",
        "test_output, test_input = test.iloc[:, 0], test.iloc[:, 1:]\n",
        "\n",
        "train_input = train_input.astype(np.float32) / 255.0\n",
        "train_output = train_output.astype(int)\n",
        "\n",
        "test_input = test_input.astype(np.float32) / 255.0\n",
        "test_output = test_output.astype(int)"
      ],
      "metadata": {
        "id": "ZbF7ShM9TEC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input.iloc[:, 120:140]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ab6F0atbRvoy",
        "outputId": "670ee7d6-ac00-4e11-b0b5-9ab42b7b7bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       121  122       123       124       125       126       127       128  \\\n",
              "0      0.0  0.0  0.094118  0.262745  0.262745  0.070588  0.000000  0.000000   \n",
              "1      0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "2      0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3      0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4      0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
              "19995  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "19996  0.0  0.0  0.000000  0.000000  0.000000  0.043137  0.517647  0.678431   \n",
              "19997  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "19998  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "19999  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "            129       130       131       132  133  134  135  136  137  138  \\\n",
              "0      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3      0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4      0.000000  0.078431  0.807843  0.823529  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...         ...       ...       ...       ...  ...  ...  ...  ...  ...  ...   \n",
              "19995  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "19996  0.039216  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "19997  0.164706  0.917647  0.996078  0.117647  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "19998  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "19999  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "       139  140  \n",
              "0      0.0  0.0  \n",
              "1      0.0  0.0  \n",
              "2      0.0  0.0  \n",
              "3      0.0  0.0  \n",
              "4      0.0  0.0  \n",
              "...    ...  ...  \n",
              "19995  0.0  0.0  \n",
              "19996  0.0  0.0  \n",
              "19997  0.0  0.0  \n",
              "19998  0.0  0.0  \n",
              "19999  0.0  0.0  \n",
              "\n",
              "[20000 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16a43613-a2e2-4f74-927e-2a7c4be89d9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.807843</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.678431</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.917647</td>\n",
              "      <td>0.996078</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16a43613-a2e2-4f74-927e-2a7c4be89d9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16a43613-a2e2-4f74-927e-2a7c4be89d9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16a43613-a2e2-4f74-927e-2a7c4be89d9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-31a25826-ffb8-4fe6-a820-fc1eb1415e00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31a25826-ffb8-4fe6-a820-fc1eb1415e00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-31a25826-ffb8-4fe6-a820-fc1eb1415e00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_input\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": 121,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11582255851837595,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 214,\n        \"samples\": [\n          0.11372549019607843,\n          0.21176470588235294,\n          0.0392156862745098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 122,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15471670906260745,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          0.4470588235294118,\n          0.9882352941176471,\n          0.23137254901960785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 123,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19425777195727062,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 249,\n        \"samples\": [\n          0.8823529411764706,\n          0.0196078431372549,\n          0.9098039215686274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 124,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23548306140471734,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 255,\n        \"samples\": [\n          0.7647058823529411,\n          0.6470588235294118,\n          0.6666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 125,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27059011092108076,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.7803921568627451,\n          0.9921568627450981,\n          0.6627450980392157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 126,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3044063519762899,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.7215686274509804,\n          0.9882352941176471,\n          0.16862745098039217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 127,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33053885479574135,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.11764705882352941,\n          0.5843137254901961,\n          0.0196078431372549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 128,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33958272274992535,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.4588235294117647,\n          0.6196078431372549,\n          0.8196078431372549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 129,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3355805200832803,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.4196078431372549,\n          0.8196078431372549,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 130,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31871496856391385,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.3411764705882353,\n          0.9411764705882353,\n          0.8470588235294118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 131,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2934153452523089,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.4549019607843137,\n          0.24313725490196078,\n          0.9254901960784314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 132,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25508283201673826,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          0.26666666666666666,\n          0.8705882352941177,\n          0.5411764705882353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 133,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20467647853731918,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 253,\n        \"samples\": [\n          0.18823529411764706,\n          0.06274509803921569,\n          0.9137254901960784\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 134,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15380104015502175,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 247,\n        \"samples\": [\n          0.4392156862745098,\n          0.11764705882352941,\n          0.8980392156862745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 135,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11051654675035767,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 215,\n        \"samples\": [\n          0.4117647058823529,\n          0.8117647058823529,\n          0.29411764705882354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 136,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07294778636457402,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          0.13725490196078433,\n          0.3176470588235294,\n          0.8941176470588236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 137,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041793504080081346,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          0.30980392156862746,\n          0.596078431372549,\n          0.21176470588235294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 138,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01988484995935893,\n        \"min\": 0.0,\n        \"max\": 0.9921568627450981,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          0.9607843137254902,\n          0.41568627450980394,\n          0.792156862745098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 139,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012024623630134616,\n        \"min\": 0.0,\n        \"max\": 0.8666666666666667,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.23921568627450981,\n          0.03529411764705882,\n          0.6470588235294118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 140,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0016360509839216302,\n        \"min\": 0.0,\n        \"max\": 0.23137254901960785,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.23137254901960785,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "T7VRMid-TnU7",
        "outputId": "579a4977-81a3-42bc-a51d-822b20ab6e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       7\n",
              "1       2\n",
              "2       1\n",
              "3       0\n",
              "4       4\n",
              "       ..\n",
              "9995    2\n",
              "9996    3\n",
              "9997    4\n",
              "9998    5\n",
              "9999    6\n",
              "Name: 0, Length: 10000, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hot_encode(output):\n",
        "  dic = {0: [1,0,0,0,0,0,0,0,0,0], 1: [0,1,0,0,0,0,0,0,0,0], 2: [0,0,1,0,0,0,0,0,0,0], 3: [0,0,0,1,0,0,0,0,0,0], 4: [0,0,0,0,1,0,0,0,0,0], 5: [0,0,0,0,0,1,0,0,0,0], 6: [0,0,0,0,0,0,1,0,0,0], 7: [0,0,0,0,0,0,0,1,0,0], 8: [0,0,0,0,0,0,0,0,1,0], 9: [0,0,0,0,0,0,0,0,0,1]}\n",
        "  output_matrix_hotencoded = np.zeros((len(output), 10))\n",
        "  for i in range(len(output)):\n",
        "    output_matrix_hotencoded[i] = dic[output[i]]\n",
        "  return output_matrix_hotencoded"
      ],
      "metadata": {
        "id": "L8tu0FKxUo7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "epochs = 50\n",
        "learning_rate = 0.1\n",
        "\n",
        "weight_matrix_1 = np.random.randn(784,128) * np.sqrt(2/784) #(784 x 128)\n",
        "bias_matrix_1 = np.zeros((1, 128)) #(1 x 128)\n",
        "\n",
        "weight_matrix_2 = np.random.randn(128,10)  * np.sqrt(2/128) #(128 x 10)\n",
        "bias_matrix_2 = np.zeros((1, 10)) #(1 x 10)\n",
        "\n",
        "# train_input_matrix = train_input[index:index+batch_size]\n",
        "# train_output_matrix = train_output[index:index + batch_size]\n",
        "\n",
        "train_input, train_output = np.array(train_input), np.array(train_output)\n",
        "test_input, test_output = np.array(test_input), np.array(test_output)\n",
        "train_output_matrix_hotencoded = hot_encode(train_output)\n",
        "test_output_matrix_hotencoded = hot_encode(test_output)\n"
      ],
      "metadata": {
        "id": "Yx5PvoZMCWSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(relu_input):\n",
        "  return np.maximum(0, relu_input)\n"
      ],
      "metadata": {
        "id": "NEhGvZj_az8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softMax(softMax_input):\n",
        "  return np.exp(softMax_input) / np.sum(np.exp(softMax_input), axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "q8GHEjc-c97p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(softMax_output, train_output):\n",
        "  return -np.sum(train_output * np.log(softMax_output))"
      ],
      "metadata": {
        "id": "J56meuNfocH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ssr(train_output_matrix_hotencoded, logits):\n",
        "    return 0.5 * np.mean((train_output_matrix_hotencoded - logits)**2)"
      ],
      "metadata": {
        "id": "ixy7IoSUSMBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcbb49bd"
      },
      "source": [
        "def forward_propagation(weight_matrix_1, bias_matrix_1, weight_matrix_2, bias_matrix_2, train_input_batch):\n",
        "\n",
        "  relu_input = train_input_batch @ weight_matrix_1 + bias_matrix_1 #(1000 x 128)\n",
        "  relu_output = ReLU(relu_input) #(1000 x 128)\n",
        "\n",
        "  logits = relu_output @ weight_matrix_2 + bias_matrix_2 #(1000 x 10)\n",
        "  # softMax_output = softMax(softMax_input) #(1000 x 10)\n",
        "\n",
        "  return relu_input, relu_output, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_propagation(weight_matrix_1, bias_matrix_1, weight_matrix_2, bias_matrix_2, relu_input, relu_output, train_input_batch, train_output_batch, logits, learning_rate):\n",
        "\n",
        "  batch_size = train_input_batch.shape[0]\n",
        "\n",
        "  dlogits = (logits - train_output_batch) / batch_size #(1000 x 10)\n",
        "\n",
        "  db2 = np.sum(dlogits, axis = 0, keepdims=True) #(1 x 10)\n",
        "  dW2 = (relu_output.T @ dlogits) #(128 x 10)\n",
        "  db1 = np.sum(dlogits @ weight_matrix_2.T * (relu_input > 0), axis = 0, keepdims=True) #(1 x 128)\n",
        "  dW1 = (train_input_batch.T @ (dlogits @ weight_matrix_2.T * (relu_input > 0))) #(784 x 128)\n",
        "\n",
        "  weight_matrix_1 -= learning_rate * dW1\n",
        "  bias_matrix_1 -= learning_rate * db1\n",
        "  weight_matrix_2 -= learning_rate * dW2\n",
        "  bias_matrix_2 -= learning_rate * db2\n",
        "\n",
        "  return weight_matrix_1, bias_matrix_1, weight_matrix_2, bias_matrix_2"
      ],
      "metadata": {
        "id": "lqEmJvE6DOZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  perm = np.random.permutation(len(train_input))\n",
        "  train_input = train_input[perm]\n",
        "  train_output_matrix_hotencoded = train_output_matrix_hotencoded[perm]\n",
        "\n",
        "  total_correct = 0\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for index in range(0, len(train_input), batch_size):\n",
        "    train_input_batch = train_input[index:index+batch_size]\n",
        "    train_output_batch = train_output_matrix_hotencoded[index:index+batch_size]\n",
        "\n",
        "    relu_input, relu_output, logits = forward_propagation(weight_matrix_1, bias_matrix_1, weight_matrix_2, bias_matrix_2, train_input_batch)\n",
        "    new_weight_matrix_1, new_bias_matrix_1, new_weight_matrix_2, new_bias_matrix_2 = back_propagation(weight_matrix_1, bias_matrix_1, weight_matrix_2, bias_matrix_2, relu_input, relu_output, train_input_batch, train_output_batch, logits, learning_rate)\n",
        "\n",
        "    weight_matrix_1 = new_weight_matrix_1\n",
        "    bias_matrix_1 = new_bias_matrix_1\n",
        "    weight_matrix_2 = new_weight_matrix_2\n",
        "    bias_matrix_2 = new_bias_matrix_2\n",
        "\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    labels = np.argmax(train_output_batch, axis=1)\n",
        "    total_correct += np.sum(preds == labels)\n",
        "    total_loss += ssr(train_output_batch, logits) * len(train_input_batch)  # weight by batch size\n",
        "\n",
        "  print(f\"Epoch {epoch+1}: train_acc={total_correct/len(train_input):.4f}  train_loss={total_loss/len(train_input):.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH_B751ujbKH",
        "outputId": "5df584c3-7989-427d-88a1-6249f198dcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_acc=0.9351  train_loss=0.009008\n",
            "Epoch 2: train_acc=0.9355  train_loss=0.008954\n",
            "Epoch 3: train_acc=0.9354  train_loss=0.008895\n",
            "Epoch 4: train_acc=0.9365  train_loss=0.008845\n",
            "Epoch 5: train_acc=0.9369  train_loss=0.008793\n",
            "Epoch 6: train_acc=0.9374  train_loss=0.008744\n",
            "Epoch 7: train_acc=0.9381  train_loss=0.008692\n",
            "Epoch 8: train_acc=0.9384  train_loss=0.008647\n",
            "Epoch 9: train_acc=0.9383  train_loss=0.008599\n",
            "Epoch 10: train_acc=0.9393  train_loss=0.008553\n",
            "Epoch 11: train_acc=0.9397  train_loss=0.008509\n",
            "Epoch 12: train_acc=0.9395  train_loss=0.008468\n",
            "Epoch 13: train_acc=0.9403  train_loss=0.008425\n",
            "Epoch 14: train_acc=0.9407  train_loss=0.008382\n",
            "Epoch 15: train_acc=0.9413  train_loss=0.008343\n",
            "Epoch 16: train_acc=0.9414  train_loss=0.008304\n",
            "Epoch 17: train_acc=0.9415  train_loss=0.008265\n",
            "Epoch 18: train_acc=0.9419  train_loss=0.008230\n",
            "Epoch 19: train_acc=0.9423  train_loss=0.008189\n",
            "Epoch 20: train_acc=0.9427  train_loss=0.008153\n",
            "Epoch 21: train_acc=0.9427  train_loss=0.008120\n",
            "Epoch 22: train_acc=0.9434  train_loss=0.008084\n",
            "Epoch 23: train_acc=0.9435  train_loss=0.008052\n",
            "Epoch 24: train_acc=0.9438  train_loss=0.008016\n",
            "Epoch 25: train_acc=0.9437  train_loss=0.007986\n",
            "Epoch 26: train_acc=0.9438  train_loss=0.007951\n",
            "Epoch 27: train_acc=0.9444  train_loss=0.007921\n",
            "Epoch 28: train_acc=0.9446  train_loss=0.007889\n",
            "Epoch 29: train_acc=0.9447  train_loss=0.007860\n",
            "Epoch 30: train_acc=0.9450  train_loss=0.007829\n",
            "Epoch 31: train_acc=0.9459  train_loss=0.007798\n",
            "Epoch 32: train_acc=0.9460  train_loss=0.007770\n",
            "Epoch 33: train_acc=0.9462  train_loss=0.007743\n",
            "Epoch 34: train_acc=0.9462  train_loss=0.007712\n",
            "Epoch 35: train_acc=0.9469  train_loss=0.007686\n",
            "Epoch 36: train_acc=0.9468  train_loss=0.007658\n",
            "Epoch 37: train_acc=0.9468  train_loss=0.007634\n",
            "Epoch 38: train_acc=0.9472  train_loss=0.007606\n",
            "Epoch 39: train_acc=0.9475  train_loss=0.007579\n",
            "Epoch 40: train_acc=0.9479  train_loss=0.007554\n",
            "Epoch 41: train_acc=0.9480  train_loss=0.007529\n",
            "Epoch 42: train_acc=0.9482  train_loss=0.007505\n",
            "Epoch 43: train_acc=0.9480  train_loss=0.007480\n",
            "Epoch 44: train_acc=0.9489  train_loss=0.007455\n",
            "Epoch 45: train_acc=0.9489  train_loss=0.007430\n",
            "Epoch 46: train_acc=0.9489  train_loss=0.007405\n",
            "Epoch 47: train_acc=0.9498  train_loss=0.007386\n",
            "Epoch 48: train_acc=0.9499  train_loss=0.007361\n",
            "Epoch 49: train_acc=0.9503  train_loss=0.007338\n",
            "Epoch 50: train_acc=0.9503  train_loss=0.007317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "\n",
        "batch = 1\n",
        "\n",
        "for index in range(0, len(test_input), batch_size):\n",
        "\n",
        "  total_loss = 0.0\n",
        "\n",
        "  test_input_batch = test_input[index:index+batch_size]\n",
        "  test_output_batch = test_output_matrix_hotencoded[index:index+batch_size]\n",
        "\n",
        "  relu_input, relu_output, logits = forward_propagation(\n",
        "      weight_matrix_1, bias_matrix_1, weight_matrix_2, bias_matrix_2,\n",
        "      test_input_batch,\n",
        "  )\n",
        "\n",
        "  preds = np.argmax(logits, axis=1)\n",
        "  labels = np.argmax(test_output_batch, axis=1)\n",
        "  total_correct += np.sum(preds == labels)\n",
        "  total_loss = ssr(test_output_batch, logits) * len(test_input_batch)\n",
        "\n",
        "  print(f\"Batch {batch}: train_loss={total_loss/len(test_input_batch):.6f}\")\n",
        "  batch += 1\n",
        "\n",
        "print(\"Test accuracy:\", total_correct / len(test_input))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhYDFaSyu9YW",
        "outputId": "a29869c4-31e5-4e94-860b-d6bb35e5ea6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: train_loss=0.008925\n",
            "Batch 2: train_loss=0.010454\n",
            "Batch 3: train_loss=0.009373\n",
            "Batch 4: train_loss=0.009405\n",
            "Batch 5: train_loss=0.009329\n",
            "Batch 6: train_loss=0.006264\n",
            "Batch 7: train_loss=0.006537\n",
            "Batch 8: train_loss=0.005732\n",
            "Batch 9: train_loss=0.004999\n",
            "Batch 10: train_loss=0.007828\n",
            "Test accuracy: 0.9405\n"
          ]
        }
      ]
    }
  ]
}